{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First check java version \n",
    "```\n",
    "$ java -version\n",
    "```\n",
    "\n",
    "2. Update ssh key \n",
    "```\n",
    "$ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa\n",
    "$ cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys\n",
    "```\n",
    "\n",
    "3. Check if you can ssh localhost without password \n",
    "```\n",
    "$ ssh localhost\n",
    "```\n",
    "\n",
    "4. Download Hadoop binary and unzip it to a dir we will call HADOOP_HOME  \n",
    "\n",
    "5. Find your Java Home directory  \n",
    "    - On OS X  - /usr/libexec/java_home   \n",
    "    - On Linux - depends on where you have installed  \n",
    "    - If its oracle JDK , then  /usr/lib/jvm/java-8-oracle/jre/  \n",
    "    - Add path to **~/.bashrc**:\n",
    "  ```\n",
    "  JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home\n",
    "  ```\n",
    "    - Also add hadoop home dir and bin dir to the file:\n",
    "    ```\n",
    "    HADOOP_HOME=/opt/hadoop-2.8.0\n",
    "    PATH=$MAVEN_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$SPARK_HOME/bin:$PATH\n",
    "    ```\n",
    "\n",
    "6. Go to **HADOOP_HOME/etc/hadoop/hadoop-env.sh**  \n",
    "  Update the JAVA_HOME to your java home directory\n",
    "  ```\n",
    "    # The java implementation to use.\n",
    "    export JAVA_HOME=${JAVA_HOME}\n",
    "  ```\n",
    "\n",
    "7. Update **HADOOP_HOME/etc/hadoop/core-site.xml**\n",
    "```\n",
    "<configuration>\n",
    "    <property>\n",
    "        <name>fs.defaultFS</name>\n",
    "        <value>hdfs://localhost:9000</value>\n",
    "    </property>\n",
    "</configuration>\n",
    "```\n",
    "\n",
    "8. Update **HADOOP_HOME/etc/hadoop/hdfs-site.xml**\n",
    "```\n",
    "<configuration>\n",
    "    <property>\n",
    "        <name>dfs.replication</name>\n",
    "        <value>1</value>\n",
    "    </property>\n",
    "</configuration>\n",
    "```\n",
    "\n",
    "9. Update **HADOOP_HOME/etc/hadoop/mapred-site.xml**\n",
    "```\n",
    "<configuration>\n",
    "    <property>\n",
    "        <name>mapreduce.framework.name</name>\n",
    "        <value>yarn</value>\n",
    "    </property>\n",
    "</configuration>\n",
    "```\n",
    "\n",
    "10. Update **HADOOP_HOME/etc/hadoop/yarn-site.xml**\n",
    "```\n",
    "<configuration>\n",
    "    <property>\n",
    "        <name>yarn.nodemanager.aux-services</name>\n",
    "        <value>mapreduce_shuffle</value>\n",
    "    </property>\n",
    "</configuration>\n",
    "```\n",
    "\n",
    "11. At command line, navigate to the hadoop home directory and run \n",
    "```\n",
    "$ bin/hdfs namenode -format \n",
    "$ sbin/start-dfs.sh\n",
    "$ sbin/start-yarn.sh \n",
    "```\n",
    "\n",
    "12. Run jps to test status  \n",
    "```\n",
    "$ jps\n",
    "```\n",
    "\n",
    "12. When you are done with your work \n",
    "```\n",
    "$ sbin/stop-dfs.sh\n",
    "$ sbin/stop-yarn.sh\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
